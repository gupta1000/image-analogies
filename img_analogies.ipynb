{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "img-analogies.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gupta1000/image-analogies/blob/master/img_analogies.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KNzkbMntIrK",
        "colab_type": "text"
      },
      "source": [
        "# CS445 Final Project: Image Analogies\n",
        "#### Michael Kokkines (mgk3) & Kush Gupta (kg3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "me5xCwwuwjq8",
        "colab_type": "text"
      },
      "source": [
        "Something about image analogies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHua2J0bI2Ud",
        "colab_type": "text"
      },
      "source": [
        "**Setup**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1aVC3XNtIrO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from scipy import signal\n",
        "\n",
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFRo0qglHQ1C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install annoy\n",
        "from annoy import AnnoyIndex"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hi2QIiuGH0ib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "A_fname = \"fall.jpg\"\n",
        "Ap_fname = \"fall_p.jpg\"\n",
        "B_fname = \"hoiem.png\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1Bm1bWcLyX2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "A = cv2.imread(A_fname, cv2.IMREAD_UNCHANGED)\n",
        "A = cv2.cvtColor(A, cv2.COLOR_GRAY2RGB)\n",
        "cv2_imshow(A)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8p1jGoppH-kX",
        "colab": {}
      },
      "source": [
        "A_p = cv2.imread(Ap_fname, cv2.IMREAD_UNCHANGED)\n",
        "A_p = cv2.cvtColor(A_p, cv2.COLOR_GRAY2RGB)\n",
        "cv2_imshow(A_p)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ITykgYyMH-ui",
        "colab": {}
      },
      "source": [
        "B = cv2.imread(B_fname, cv2.IMREAD_UNCHANGED)\n",
        "cv2_imshow(B)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-txWZqxxNIZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# levels\n",
        "L = 3 \n",
        "\n",
        "# We typically use 2 ≤ K ≤ 25 for color non-photorealistic filters,\n",
        "# K = 1 for line art filters, and 0.5 ≤ K ≤ 5 for texture synthesis.\n",
        "\n",
        "# K = .5   # luminance\n",
        "# K = -1   # contrast\n",
        "# K = -1   # recolorize\n",
        "# K = -1   # color adjust\n",
        "# K = -0.5 # texture transfer\n",
        "\n",
        "K = -.32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdprjE_FvLwV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "b_p_f = create_image_analogy(A, A_p, B, L)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "u5C7sqZnqq8W",
        "colab": {}
      },
      "source": [
        "b_p = reconstruct_luminance(b_p_f[L-1], B)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oi4Ft25dqvJf",
        "colab": {}
      },
      "source": [
        "cv2_imshow(B)\n",
        "cv2_imshow(cv2.cvtColor(b_p_f[2].astype('float32'), cv2.COLOR_LAB2BGR) * 255)\n",
        "cv2_imshow(b_p)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y357FlCAIlu0",
        "colab_type": "text"
      },
      "source": [
        "**Gaussian Computation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONdec00D5-qM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gaussian_kernel(sigma, kernel_half_size):\n",
        "    window_size = kernel_half_size*2+1\n",
        "    gaussian_kernel_1d = signal.gaussian(window_size, std=sigma).reshape(window_size, 1)\n",
        "    gaussian_kernel_2d = np.outer(gaussian_kernel_1d, gaussian_kernel_1d)\n",
        "    gaussian_kernel_2d /= np.sum(gaussian_kernel_2d)\n",
        "    return gaussian_kernel_2d"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjC8TqFyIVya",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gaussian_pyr(im, levels):\n",
        "  images = [ im ]\n",
        "  kernel = gaussian_kernel(4, 16)\n",
        "\n",
        "  for i in range(levels - 1):\n",
        "    prev_img = cv2.resize(\n",
        "      signal.convolve2d(\n",
        "          images[-1], \n",
        "          kernel, \n",
        "          boundary=\"symm\", \n",
        "          mode=\"same\"\n",
        "        ),\n",
        "        None, \n",
        "        fx=.5, \n",
        "        fy=.5\n",
        "    )\n",
        "    images.append(prev_img)\n",
        "  \n",
        "  return images\n",
        "\n",
        "\n",
        "def gaussian_pyr_rgb(im, levels):\n",
        "  red_images = gaussian_pyr(im[:, :, 0], levels)\n",
        "  green_images = gaussian_pyr(im[:, :, 1], levels)\n",
        "  blue_images = gaussian_pyr(im[:, :, 2], levels)\n",
        "\n",
        "  images = []\n",
        "  for i in range(len(red_images)):\n",
        "    img = np.zeros((red_images[i].shape[0], red_images[i].shape[1], 3))\n",
        "    img[:, :, 0] = red_images[i]\n",
        "    img[:, :, 1] = green_images[i]\n",
        "    img[:, :, 2] = blue_images[i]\n",
        "    images.append(img)\n",
        "  \n",
        "  return images[::-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0BSS-ieIZOO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_gaussians(A, A_p, B, L):\n",
        "  a = gaussian_pyr_rgb(A, L)\n",
        "  a_p = gaussian_pyr_rgb(A_p, L)\n",
        "  b = gaussian_pyr_rgb(B, L)\n",
        "  return a, a_p, b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQTN7SYeIoyH",
        "colab_type": "text"
      },
      "source": [
        "**Feature Computation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFrsIOclDASb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_features = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gg3ii3XnIgqi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_features(im):\n",
        "  feature_vec = np.zeros((im.shape[0], im.shape[1], num_features))\n",
        "\n",
        "  # extract luminance\n",
        "  lab_im = cv2.cvtColor((im/255).astype('float32'), cv2.COLOR_BGR2LAB)\n",
        "  feature_vec[:,:,0:3] = lab_im\n",
        "\n",
        "  # # Add the RGB channels\n",
        "  # feature_vec[:,:,1:4] = im\n",
        "\n",
        "  return feature_vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQQunXVIIrH2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_featuresets(a, a_p, b, L):\n",
        "  a_feat = []\n",
        "  a_p_feat = []\n",
        "  b_feat = []\n",
        "  b_p_feat = []\n",
        "  s = []\n",
        "  for l in range(L):\n",
        "    a_feat.append(compute_features(a[l]))\n",
        "    a_p_feat.append(compute_features(a_p[l]))\n",
        "    b_feat.append(compute_features(b[l]))\n",
        "    b_p_feat.append(np.zeros(b_feat[-1].shape))\n",
        "    s.append(np.zeros((b_feat[-1].shape[0], b_feat[-1].shape[1], 2)))\n",
        "  return a_feat, a_p_feat, b_feat, b_p_feat, s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXvqHCpbJ-Lr",
        "colab_type": "text"
      },
      "source": [
        "**Pixel Matching**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5crHA3Js_Ar",
        "colab_type": "text"
      },
      "source": [
        "*Approximate Matching*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUmFHPnKiHLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rob_neighborhood(im, p, fine_bound=2):\n",
        "  p_x = int(p[0])\n",
        "  p_y = int(p[1])\n",
        "\n",
        "  # move window center if given point is too close to edge\n",
        "  if (p_x - fine_bound < 0):\n",
        "    p_x = fine_bound\n",
        "  if (p_x + fine_bound >= im.shape[1]):\n",
        "    p_x = im.shape[1] - fine_bound - 1\n",
        "  if (p_y - fine_bound < 0):\n",
        "    p_y = fine_bound\n",
        "  if (p_y + fine_bound >= im.shape[0]):\n",
        "    p_y = im.shape[0] - fine_bound -1\n",
        "\n",
        "  return normalize_f(im[p_y-fine_bound:p_y+fine_bound+1, p_x-fine_bound:p_x+fine_bound+1]).flatten()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oyejjc5WL06S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plant_forest(im, L):\n",
        "  forests = []\n",
        "  pixel_maps = []\n",
        "\n",
        "  for l in range(L):\n",
        "    # We decided to use Manhattan distance\n",
        "    ann = AnnoyIndex(3*5*5, \"manhattan\")\n",
        "    \n",
        "    # Initialize the pixel map\n",
        "    num_indices = im[l].shape[0] * im[l].shape[1] \n",
        "    index_to_pixel = np.zeros((num_indices, 2))\n",
        "\n",
        "    lab = cv2.cvtColor((im[l] / 255.0).astype(\"float32\"), cv2.COLOR_BGR2LAB)\n",
        "      \n",
        "    i = 0\n",
        "    for r in range(im[l].shape[0]):\n",
        "      for c in range(im[l].shape[1]):\n",
        "        ann.add_item(i, rob_neighborhood(lab, (c, r)))\n",
        "        index_to_pixel[i, :] = np.array([c, r])\n",
        "        i += 1\n",
        "    \n",
        "    # Create a forest of ten trees\n",
        "    ann.build(10)\n",
        "    forests.append(ann)\n",
        "    pixel_maps.append(index_to_pixel)\n",
        "  \n",
        "  return forests, pixel_maps"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jay1Kapfs6Ih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def best_approx_match(forest, pixel_map, b, q):\n",
        "  index = forest.get_nns_by_vector(rob_neighborhood(b,q), 1, search_k=forest.get_n_items())[0]\n",
        "  return pixel_map[index].astype('int32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAvm3q4uvps3",
        "colab_type": "text"
      },
      "source": [
        "*Feature Distance*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWsmhcbQldFb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize_f(f):\n",
        "  # print(f)\n",
        "  norm = np.zeros(f.shape)\n",
        "  gk = gaussian_kernel(f.shape[0]/10, int(f.shape[0]/2))\n",
        "  for i in range(num_features):\n",
        "    norm[:,:,i] = f[:,:,i] * gk\n",
        "  return norm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hC3V1GVeUick",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: make this not the most horrible thing in existance\n",
        "def concat_feat(fpyr, p, l, fine_bound=2, coarse_bound=1):\n",
        "  p_x = int(p[0])\n",
        "  p_y = int(p[1])\n",
        "  lpyr = fpyr[l]\n",
        "  f_coarse = np.zeros((2 * coarse_bound + 1)**2*num_features)\n",
        "\n",
        "  # move window center if given point is too close to edge\n",
        "  if (p_x - fine_bound < 0):\n",
        "    p_x = fine_bound\n",
        "  if (p_x + fine_bound >= fpyr[l].shape[1]):\n",
        "    p_x = fpyr[l].shape[1] - fine_bound - 1\n",
        "  if (p_y - fine_bound < 0):\n",
        "    p_y = fine_bound\n",
        "  if (p_y + fine_bound >= fpyr[l].shape[0]):\n",
        "    p_y = fpyr[l].shape[0] - fine_bound -1\n",
        "\n",
        "  f = normalize_f(lpyr[p_y-fine_bound:p_y+fine_bound+1, p_x-fine_bound:p_x+fine_bound+1]).flatten()\n",
        "\n",
        "  if (l > 0):\n",
        "    p_x = int(p_x/2)\n",
        "    p_y = int(p_y/2)\n",
        "\n",
        "    # move window center if given point is too close to edge\n",
        "    if (p_x - coarse_bound < 0):\n",
        "      p_x += coarse_bound\n",
        "    if (p_x + coarse_bound >= fpyr[l-1].shape[1]):\n",
        "      p_x -= coarse_bound\n",
        "    if (p_y - coarse_bound < 0):\n",
        "      p_y += coarse_bound\n",
        "    if (p_y + coarse_bound >= fpyr[l-1].shape[0]):\n",
        "      p_y -= coarse_bound\n",
        "      \n",
        "    f_coarse = normalize_f(fpyr[l-1][p_y-coarse_bound:p_y+coarse_bound+1,p_x-coarse_bound:p_x+coarse_bound+1]).flatten()\n",
        "  \n",
        "  return np.concatenate((f, f_coarse), axis=0) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvjkFeIWluYe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def F_l(a_f, a_p_f, p, l):\n",
        "  return np.concatenate((concat_feat(a_f, p, l), concat_feat(a_p_f, p, l)), axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_zEWgw5vpzc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def feature_dist(a_f, a_p_f, b_f, b_p_f, p, q, l, fine_bound=2, coarse_bound=1):\n",
        "  return np.linalg.norm(F_l(a_f, a_p_f, p, l) - F_l(b_f, b_p_f, q, l), ord=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3XSNvh7tEAS",
        "colab_type": "text"
      },
      "source": [
        "*Coherence Matching*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZYyzk_qs3es",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def best_coherence_match(a_f, a_p_f, b_f, b_p_f, s, q, l, N=2):\n",
        "  min_dist = float('inf')\n",
        "  match = [-1, -1]\n",
        "  for r in range(q[1]-N,q[1]+1):\n",
        "    for c in range(q[0]-N,q[0]+N):\n",
        "      # do not consider pixels outside of image boundary (cannot go below q because scan-line order)\n",
        "      if (r < 0 or c < 0 or c >= a_f[l].shape[1]): continue\n",
        "      # break when current pixel is reached, to only consider previously synthesied pixels\n",
        "      if (q == (c, r)): return np.array(match).astype('int32'), min_dist\n",
        "\n",
        "      # get corresponding pixel based on previous match and relative position \n",
        "      fsr = (s[l][r,c] + q - [c,r])\n",
        "      # skip match if it is outside bounds of source image\n",
        "      if (fsr[0] < 0 or fsr[1] < 0 or fsr[0] >= a_f[l].shape[1] or fsr[1] >= a_f[l].shape[0]): continue\n",
        "\n",
        "      # compute distance between potential match and current\n",
        "      d = feature_dist(a_f, a_p_f, b_f, b_p_f, fsr, q, l)\n",
        "\n",
        "      # argmin\n",
        "      if (d < min_dist):\n",
        "        min_dist = d\n",
        "        match = fsr\n",
        "      \n",
        "  return np.array(match).astype('int32'), min_dist\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0_-CLCZtJHb",
        "colab_type": "text"
      },
      "source": [
        "*Matching Core*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSgOI3fnKA3q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def best_match(a_f, a_p_f, b_f, b_p_f, a_forest, pixel_maps, s, q, l, lab, N=2):\n",
        "  p_app = best_approx_match(a_forest[l], pixel_maps[l], lab, q)\n",
        "\n",
        "  # if near image boundary, skip coherence method\n",
        "  if (q[0] < N or q[1] < N or q[0] + N >= b_p_f[l].shape[1] or q[1] + N >= b_p_f[l].shape[0]):\n",
        "    return p_app, \"app\"\n",
        "\n",
        "  p_coh, dist_coh = best_coherence_match(a_f, a_p_f, b_f, b_p_f, s, q, l, N)\n",
        "  if (p_coh[0] == -1 and p_coh[1] == -1):\n",
        "    return p_app, \"app\"\n",
        "\n",
        "  dist_app = feature_dist(a_f, a_p_f, b_f, b_p_f, p_app, q, l)\n",
        "\n",
        "  if (dist_coh <= (dist_app * (1 + 2**(l - L) * K))):\n",
        "    return p_coh, \"coh\" \n",
        "  return p_app, \"app\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-GteATpKFUK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def match_all(a_f, a_p_f, b_f, b_p_f, b, a_forest, pixel_maps, s, L):\n",
        "  i = 0\n",
        "  for l in range(L):\n",
        "    lab = cv2.cvtColor((b[l] / 255.0).astype(\"float32\"), cv2.COLOR_BGR2LAB)\n",
        "    for q_y in range(b_f[l].shape[0]):\n",
        "      for q_x in range(b_f[l].shape[1]):\n",
        "        p, method = best_match(a_f, a_p_f, b_f, b_p_f, a_forest, pixel_maps, s, (q_x, q_y), l, lab)\n",
        "        b_p_f[l][q_y,q_x] = a_p_f[l][p[1],p[0]]\n",
        "        s[l][q_y,q_x] = p\n",
        "        if (i%1024==0): print(\"matched A\" + str(p) + \" to B[\" + str(q_x) + \" \" + str(q_y) + \"] using \" + method + \" @l(\" + str(l) + \") - \" + str(a_p_f[l][p[1],p[0]])) \n",
        "        i+=1\n",
        "  return b_p_f"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srj2sBt2Iqf3",
        "colab_type": "text"
      },
      "source": [
        "**Image Analogies Core**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBeCccN5JdHU",
        "colab_type": "text"
      },
      "source": [
        "Automated Runs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRERY888FC9t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create image analogy for image B using references A : A_p\n",
        "# using a gaussian pyramid of the specified number of levels 'L'\n",
        "def create_image_analogy(A, A_p, B, L):\n",
        "\n",
        "  # step 1: create gaussian pyramids for A, A_p, and B\n",
        "  a, a_p, b = build_gaussians(A, A_p, B, L)\n",
        "  # step 2: compute features for A, A_p, and B\n",
        "  a_f, a_p_f, b_f, b_p_f, s = compute_featuresets(a, a_p, b, L)\n",
        "  # step 3: init ann\n",
        "  a_forest, pixel_maps = plant_forest(a, L)\n",
        "\n",
        "  # step 4: solve for best matches\n",
        "  b_p_f = match_all(a_f, a_p_f, b_f, b_p_f, b, a_forest, pixel_maps, s, L)\n",
        "\n",
        "  return b_p_f"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfDJwTdIyfUo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this reconstruction will work on luminance filter analogies\n",
        "def reconstruct_luminance(pyr, B):\n",
        "  lab = cv2.cvtColor((B/255.0).astype(\"float32\"), cv2.COLOR_BGR2LAB)\n",
        "  lab[:,:,0] = pyr[:,:,0]\n",
        "  lab = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n",
        "  return lab * 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rA7gs86DJa0o",
        "colab_type": "text"
      },
      "source": [
        "Unit Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5it2AejJJxnC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a, a_p, b = build_gaussians(A, A_p, B, L)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1l2D7miFz9QS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cv2_imshow(b[0])\n",
        "cv2_imshow(b[1])\n",
        "cv2_imshow(b[2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qo-hNhwxJ3zM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a_f, a_p_f, b_f, b_p_f, s = compute_featuresets(a, a_p, b, L)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvMXpM62WZjw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a_forest, pixel_maps = plant_forest(a, L)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShrBD-AeKiaI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "b_p_f = match_all(a_f, a_p_f, b_f, b_p_f, b, a_forest, pixel_maps, s, L)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOxc0j4Y6Ier",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "b_p = reconstruct_luminance(b_p_f[L-1], B)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZBmlMOx6liV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cv2_imshow(b[2])\n",
        "cv2_imshow(cv2.cvtColor(a_p_f[2].astype('float32'), cv2.COLOR_LAB2BGR) * 255)\n",
        "cv2_imshow(cv2.cvtColor(b_p_f[2].astype('float32'), cv2.COLOR_LAB2BGR) * 255)\n",
        "cv2_imshow(b_p)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}